--------------------------------------------------------------------
Java options: -Dspark.storage.memoryFraction=0.66 -Dspark.serializer=org.apache.spark.serializer.JavaSerializer -Dspark.locality.wait=60000000
Options: SortByKey --num-trials=10 --inter-trial-wait=3 --num-partitions=2 --reduce-tasks=2 --random-seed=5 --persistent-type=memory  --num-records=1000000 --unique-keys=100 --key-length=10 --unique-values=5000 --value-length=10  --storage-location=hdfs://spark-master:9000/test//spark-perf-kv-data
--------------------------------------------------------------------
20/10/09 01:58:13 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
20/10/09 01:58:13 DEBUG NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
20/10/09 01:58:13 DEBUG NativeCodeLoader: java.library.path=:/lib/native:/usr/java/packages/lib/i386:/usr/lib/i386-linux-gnu/jni:/lib/i386-linux-gnu:/usr/lib/i386-linux-gnu:/usr/lib/jni:/lib:/usr/lib
20/10/09 01:58:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/10/09 01:58:14 INFO SparkContext: Running Spark version 2.4.6
20/10/09 01:58:14 WARN SparkConf: Detected deprecated memory fraction settings: [spark.storage.memoryFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended).
20/10/09 01:58:14 INFO SparkContext: Submitted application: TestRunner
20/10/09 01:58:14 INFO SecurityManager: Changing view acls to: root,spark
20/10/09 01:58:14 INFO SecurityManager: Changing modify acls to: root,spark
20/10/09 01:58:14 INFO SecurityManager: Changing view acls groups to: 
20/10/09 01:58:14 INFO SecurityManager: Changing modify acls groups to: 
20/10/09 01:58:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root, spark); groups with view permissions: Set(); users  with modify permissions: Set(root, spark); groups with modify permissions: Set()
20/10/09 01:58:14 INFO Utils: Successfully started service 'sparkDriver' on port 44657.
20/10/09 01:58:14 INFO SparkEnv: Registering MapOutputTracker
20/10/09 01:58:14 INFO SparkEnv: Registering BlockManagerMaster
20/10/09 01:58:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/10/09 01:58:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/10/09 01:58:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-38d9422b-390d-4d7e-aa80-11b1cbce74ce
20/10/09 01:58:14 INFO MemoryStore: MemoryStore started with capacity 366.1 MB
20/10/09 01:58:14 INFO SparkEnv: Registering OutputCommitCoordinator
20/10/09 01:58:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/10/09 01:58:14 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://spark-master:4040
20/10/09 01:58:14 INFO Executor: Starting executor ID driver on host localhost
20/10/09 01:58:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36131.
20/10/09 01:58:14 INFO NettyBlockTransferService: Server created on spark-master:36131
20/10/09 01:58:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/10/09 01:58:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-master, 36131, None)
20/10/09 01:58:14 INFO BlockManagerMasterEndpoint: Registering block manager spark-master:36131 with 366.1 MB RAM, BlockManagerId(driver, spark-master, 36131, None)
20/10/09 01:58:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-master, 36131, None)
20/10/09 01:58:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-master, 36131, None)
20/10/09 01:58:15 INFO EventLoggingListener: Logging events to file:/usr/local/spark/logs/local-1602201494785
20/10/09 01:58:15 INFO SparkContext: Starting job: count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33
20/10/09 01:58:15 INFO DAGScheduler: Got job 0 (count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33) with 2 output partitions
20/10/09 01:58:15 INFO DAGScheduler: Final stage: ResultStage 0 (count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33)
20/10/09 01:58:15 INFO DAGScheduler: Parents of final stage: List()
20/10/09 01:58:15 INFO DAGScheduler: Missing parents: List()
20/10/09 01:58:15 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33), which has no missing parents
20/10/09 01:58:15 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/10/09 01:58:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 366.1 MB)
20/10/09 01:58:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.8 KB, free 366.1 MB)
20/10/09 01:58:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-master:36131 (size: 4.8 KB, free: 366.1 MB)
20/10/09 01:58:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:16 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
20/10/09 01:58:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:16 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/10/09 01:58:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
20/10/09 01:58:18 INFO PythonRunner: Times: total = 2217, boot = 169, init = 54, finish = 1994
20/10/09 01:58:18 INFO MemoryStore: Block rdd_1_0 stored as values in memory (estimated size 5.6 MB, free 360.5 MB)
20/10/09 01:58:18 INFO BlockManagerInfo: Added rdd_1_0 in memory on spark-master:36131 (size: 5.6 MB, free: 360.6 MB)
20/10/09 01:58:18 INFO PythonRunner: Times: total = 2288, boot = 164, init = 62, finish = 2062
20/10/09 01:58:18 INFO MemoryStore: Block rdd_1_1 stored as values in memory (estimated size 5.6 MB, free 355.0 MB)
20/10/09 01:58:18 INFO BlockManagerInfo: Added rdd_1_1 in memory on spark-master:36131 (size: 5.6 MB, free: 355.0 MB)
20/10/09 01:58:18 INFO PythonRunner: Times: total = 168, boot = 3, init = 5, finish = 160
20/10/09 01:58:18 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1464 bytes result sent to driver
20/10/09 01:58:18 INFO PythonRunner: Times: total = 194, boot = 3, init = 2, finish = 189
20/10/09 01:58:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1507 bytes result sent to driver
20/10/09 01:58:18 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2702 ms on localhost (executor driver) (1/2)
20/10/09 01:58:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2726 ms on localhost (executor driver) (2/2)
20/10/09 01:58:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/10/09 01:58:18 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 54807
20/10/09 01:58:18 INFO DAGScheduler: ResultStage 0 (count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33) finished in 2.912 s
20/10/09 01:58:18 INFO DAGScheduler: Job 0 finished: count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:33, took 3.043884 s
20/10/09 01:58:19 INFO SparkContext: Starting job: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99
20/10/09 01:58:19 INFO DAGScheduler: Got job 1 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) with 2 output partitions
20/10/09 01:58:19 INFO DAGScheduler: Final stage: ResultStage 1 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99)
20/10/09 01:58:19 INFO DAGScheduler: Parents of final stage: List()
20/10/09 01:58:19 INFO DAGScheduler: Missing parents: List()
20/10/09 01:58:19 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99), which has no missing parents
20/10/09 01:58:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.9 KB, free 355.0 MB)
20/10/09 01:58:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KB, free 354.9 MB)
20/10/09 01:58:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-master:36131 (size: 4.8 KB, free: 355.0 MB)
20/10/09 01:58:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[3] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
20/10/09 01:58:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
20/10/09 01:58:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
20/10/09 01:58:19 INFO BlockManager: Found block rdd_1_1 locally
20/10/09 01:58:19 INFO BlockManager: Found block rdd_1_0 locally
20/10/09 01:58:19 INFO PythonRunner: Times: total = 186, boot = -491, init = 501, finish = 176
20/10/09 01:58:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1507 bytes result sent to driver
20/10/09 01:58:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 249 ms on localhost (executor driver) (1/2)
20/10/09 01:58:19 INFO PythonRunner: Times: total = 246, boot = -474, init = 507, finish = 213
20/10/09 01:58:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1507 bytes result sent to driver
20/10/09 01:58:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 265 ms on localhost (executor driver) (2/2)
20/10/09 01:58:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/10/09 01:58:19 INFO DAGScheduler: ResultStage 1 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) finished in 0.280 s
20/10/09 01:58:19 INFO DAGScheduler: Job 1 finished: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99, took 0.284478 s
20/10/09 01:58:19 INFO SparkContext: Starting job: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99
20/10/09 01:58:19 INFO DAGScheduler: Got job 2 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) with 2 output partitions
20/10/09 01:58:19 INFO DAGScheduler: Final stage: ResultStage 2 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99)
20/10/09 01:58:19 INFO DAGScheduler: Parents of final stage: List()
20/10/09 01:58:19 INFO DAGScheduler: Missing parents: List()
20/10/09 01:58:19 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[4] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99), which has no missing parents
20/10/09 01:58:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.5 KB, free 354.9 MB)
20/10/09 01:58:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.9 MB)
20/10/09 01:58:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-master:36131 (size: 4.5 KB, free: 355.0 MB)
20/10/09 01:58:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[4] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
20/10/09 01:58:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
20/10/09 01:58:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
20/10/09 01:58:19 INFO BlockManager: Found block rdd_1_0 locally
20/10/09 01:58:19 INFO BlockManager: Found block rdd_1_1 locally
20/10/09 01:58:19 INFO PythonRunner: Times: total = 279, boot = -143, init = 157, finish = 265
20/10/09 01:58:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 1755 bytes result sent to driver
20/10/09 01:58:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 305 ms on localhost (executor driver) (1/2)
20/10/09 01:58:19 INFO PythonRunner: Times: total = 415, boot = -143, init = 271, finish = 287
20/10/09 01:58:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1857 bytes result sent to driver
20/10/09 01:58:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 452 ms on localhost (executor driver) (2/2)
20/10/09 01:58:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/10/09 01:58:19 INFO DAGScheduler: ResultStage 2 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) finished in 0.477 s
20/10/09 01:58:19 INFO DAGScheduler: Job 2 finished: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99, took 0.481152 s
20/10/09 01:58:20 INFO SparkContext: Starting job: count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99
20/10/09 01:58:20 INFO DAGScheduler: Registering RDD 6 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) as input to shuffle 0
20/10/09 01:58:20 INFO DAGScheduler: Got job 3 (count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) with 2 output partitions
20/10/09 01:58:20 INFO DAGScheduler: Final stage: ResultStage 4 (count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99)
20/10/09 01:58:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/10/09 01:58:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/10/09 01:58:20 INFO DAGScheduler: Submitting ShuffleMapStage 3 (PairwiseRDD[6] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99), which has no missing parents
20/10/09 01:58:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 9.2 KB, free 354.9 MB)
20/10/09 01:58:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KB, free 354.9 MB)
20/10/09 01:58:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-master:36131 (size: 5.8 KB, free: 355.0 MB)
20/10/09 01:58:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (PairwiseRDD[6] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:20 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
20/10/09 01:58:20 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7841 bytes)
20/10/09 01:58:20 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 7841 bytes)
20/10/09 01:58:20 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
20/10/09 01:58:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
20/10/09 01:58:20 INFO BlockManager: Found block rdd_1_1 locally
20/10/09 01:58:20 INFO BlockManager: Found block rdd_1_0 locally
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 72
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 34
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 73
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 40
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 45
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 62
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 43
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 42
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 35
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 52
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 51
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 39
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 57
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 50
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 36
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 29
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 30
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 32
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 27
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 26
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 41
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 63
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 48
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 58
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 54
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 59
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 68
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 56
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 69
20/10/09 01:58:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-master:36131 in memory (size: 4.5 KB, free: 355.0 MB)
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 46
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 74
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 70
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 65
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 67
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 55
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 49
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 60
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 33
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 47
20/10/09 01:58:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on spark-master:36131 in memory (size: 4.8 KB, free: 355.0 MB)
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 37
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 75
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 71
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 44
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 64
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 31
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 66
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 61
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 53
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 28
20/10/09 01:58:20 INFO ContextCleaner: Cleaned accumulator 38
20/10/09 01:58:21 INFO PythonRunner: Times: total = 1031, boot = -316, init = 341, finish = 1006
20/10/09 01:58:21 INFO PythonRunner: Times: total = 1094, boot = -474, init = 498, finish = 1070
20/10/09 01:58:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 1762 bytes result sent to driver
20/10/09 01:58:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 1822 ms on localhost (executor driver) (1/2)
20/10/09 01:58:22 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1719 bytes result sent to driver
20/10/09 01:58:22 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 1834 ms on localhost (executor driver) (2/2)
20/10/09 01:58:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/10/09 01:58:22 INFO DAGScheduler: ShuffleMapStage 3 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) finished in 1.928 s
20/10/09 01:58:22 INFO DAGScheduler: looking for newly runnable stages
20/10/09 01:58:22 INFO DAGScheduler: running: Set()
20/10/09 01:58:22 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/10/09 01:58:22 INFO DAGScheduler: failed: Set()
20/10/09 01:58:22 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[9] at count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99), which has no missing parents
20/10/09 01:58:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.1 KB, free 354.9 MB)
20/10/09 01:58:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KB, free 354.9 MB)
20/10/09 01:58:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-master:36131 (size: 5.0 KB, free: 355.0 MB)
20/10/09 01:58:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (PythonRDD[9] at count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:22 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
20/10/09 01:58:22 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, ANY, 7662 bytes)
20/10/09 01:58:22 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, ANY, 7662 bytes)
20/10/09 01:58:22 INFO Executor: Running task 1.0 in stage 4.0 (TID 9)
20/10/09 01:58:22 INFO Executor: Running task 0.0 in stage 4.0 (TID 8)
20/10/09 01:58:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
20/10/09 01:58:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
20/10/09 01:58:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
20/10/09 01:58:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
20/10/09 01:58:22 INFO PythonRunner: Times: total = 487, boot = -881, init = 905, finish = 463
20/10/09 01:58:22 INFO Executor: Finished task 0.0 in stage 4.0 (TID 8). 1722 bytes result sent to driver
20/10/09 01:58:22 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 556 ms on localhost (executor driver) (1/2)
20/10/09 01:58:23 INFO PythonRunner: Times: total = 867, boot = -818, init = 841, finish = 844
20/10/09 01:58:23 INFO Executor: Finished task 1.0 in stage 4.0 (TID 9). 1722 bytes result sent to driver
20/10/09 01:58:23 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 934 ms on localhost (executor driver) (2/2)
20/10/09 01:58:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/10/09 01:58:23 INFO DAGScheduler: ResultStage 4 (count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) finished in 0.946 s
20/10/09 01:58:23 INFO DAGScheduler: Job 3 finished: count at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99, took 2.906281 s
20/10/09 01:58:26 INFO SparkContext: Starting job: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99
20/10/09 01:58:26 INFO DAGScheduler: Got job 4 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) with 2 output partitions
20/10/09 01:58:26 INFO DAGScheduler: Final stage: ResultStage 5 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99)
20/10/09 01:58:26 INFO DAGScheduler: Parents of final stage: List()
20/10/09 01:58:26 INFO DAGScheduler: Missing parents: List()
20/10/09 01:58:26 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[10] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99), which has no missing parents
20/10/09 01:58:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.9 KB, free 354.9 MB)
20/10/09 01:58:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.8 KB, free 354.9 MB)
20/10/09 01:58:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on spark-master:36131 (size: 4.8 KB, free: 355.0 MB)
20/10/09 01:58:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (PythonRDD[10] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
20/10/09 01:58:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:26 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:26 INFO Executor: Running task 0.0 in stage 5.0 (TID 10)
20/10/09 01:58:26 INFO Executor: Running task 1.0 in stage 5.0 (TID 11)
20/10/09 01:58:26 INFO BlockManager: Found block rdd_1_0 locally
20/10/09 01:58:26 INFO BlockManager: Found block rdd_1_1 locally
20/10/09 01:58:26 INFO PythonRunner: Times: total = 160, boot = -3456, init = 3472, finish = 144
20/10/09 01:58:26 INFO PythonRunner: Times: total = 161, boot = -3076, init = 3092, finish = 145
20/10/09 01:58:26 INFO Executor: Finished task 0.0 in stage 5.0 (TID 10). 1507 bytes result sent to driver
20/10/09 01:58:26 INFO Executor: Finished task 1.0 in stage 5.0 (TID 11). 1507 bytes result sent to driver
20/10/09 01:58:26 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 166 ms on localhost (executor driver) (1/2)
20/10/09 01:58:26 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 166 ms on localhost (executor driver) (2/2)
20/10/09 01:58:26 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/10/09 01:58:26 INFO DAGScheduler: ResultStage 5 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) finished in 0.177 s
20/10/09 01:58:26 INFO DAGScheduler: Job 4 finished: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99, took 0.215122 s
20/10/09 01:58:26 INFO SparkContext: Starting job: sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99
20/10/09 01:58:26 INFO DAGScheduler: Got job 5 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) with 2 output partitions
20/10/09 01:58:26 INFO DAGScheduler: Final stage: ResultStage 6 (sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99)
20/10/09 01:58:26 INFO DAGScheduler: Parents of final stage: List()
20/10/09 01:58:26 INFO DAGScheduler: Missing parents: List()
20/10/09 01:58:26 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[11] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99), which has no missing parents
20/10/09 01:58:26 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.5 KB, free 354.9 MB)
20/10/09 01:58:26 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 354.9 MB)
20/10/09 01:58:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on spark-master:36131 (size: 4.5 KB, free: 354.9 MB)
20/10/09 01:58:26 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1163
20/10/09 01:58:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (PythonRDD[11] at sortByKey at /home/spark/FinalProject/SparkParameterTuning/pyspark-tests/core_tests.py:99) (first 15 tasks are for partitions Vector(0, 1))
20/10/09 01:58:26 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
20/10/09 01:58:26 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:26 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 7852 bytes)
20/10/09 01:58:26 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
20/10/09 01:58:26 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
20/10/09 01:58:26 INFO BlockManager: Found block rdd_1_1 locally
20/10/09 01:58:26 INFO BlockManager: Found block rdd_1_0 locally
